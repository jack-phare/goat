# LiteLLM proxy for goat development.
# Mirrors the agent-hub production stack so the same models and env vars work.
#
# Usage:
#   cp dev/.env.example dev/.env   # then fill in your keys
#   docker compose -f dev/docker-compose.yml up -d
#   go run ./cmd/example/ -provider litellm
#
# Check available models:
#   curl http://localhost:4000/v1/models -H "Authorization: Bearer sk-dev-key"

services:
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_DB=litellm
      - POSTGRES_USER=litellm
      - POSTGRES_PASSWORD=litellm
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U litellm"]
      interval: 5s
      timeout: 3s
      retries: 5

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    volumes:
      - ./litellm-config.yaml:/app/config.yaml
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-dev-key}
      - DATABASE_URL=postgresql://litellm:litellm@postgres:5432/litellm
      # Provider keys (leave blank if unused)
      - AZURE_API_KEY=${AZURE_API_KEY:-}
      - AZURE_API_BASE=${AZURE_API_BASE:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      # Langfuse (optional â€” leave blank to skip)
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-}
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

volumes:
  pgdata:
